{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import csv\n",
    "import requests\n",
    "from io import StringIO\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM, SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Import Dataset hasil scrapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('7dsgc_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>061a9c37-9da0-4afb-923d-b9b4f120a1e7</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>event nya banyak tambah lagi event nya terus</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.73.0</td>\n",
       "      <td>2025-03-28 12:04:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b17544bc-2268-49a5-afa7-747f4484fd59</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>lebih bagus lagi ini game mod miring deh</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.73.0</td>\n",
       "      <td>2025-03-28 01:34:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a6dcf278-4c53-4afd-ba34-ddbf9031d62e</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>bagus banget gamenya</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-03-27 22:11:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6517e761-e80e-4c8f-9e7d-40bf5092d455</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>bagus dan menghibur 3d sangat enak di lihat mata</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.73.0</td>\n",
       "      <td>2025-03-27 18:30:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0943c392-06e9-49f1-a361-aacf643c8880</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Tolong di jelaskan kenapa akun saya di ban den...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.73.0</td>\n",
       "      <td>2025-03-27 17:12:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.73.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId         userName  \\\n",
       "0  061a9c37-9da0-4afb-923d-b9b4f120a1e7  Pengguna Google   \n",
       "1  b17544bc-2268-49a5-afa7-747f4484fd59  Pengguna Google   \n",
       "2  a6dcf278-4c53-4afd-ba34-ddbf9031d62e  Pengguna Google   \n",
       "3  6517e761-e80e-4c8f-9e7d-40bf5092d455  Pengguna Google   \n",
       "4  0943c392-06e9-49f1-a361-aacf643c8880  Pengguna Google   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "3  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0       event nya banyak tambah lagi event nya terus      5              0   \n",
       "1           lebih bagus lagi ini game mod miring deh      2              0   \n",
       "2                               bagus banget gamenya      5              0   \n",
       "3   bagus dan menghibur 3d sangat enak di lihat mata      5              0   \n",
       "4  Tolong di jelaskan kenapa akun saya di ban den...      1              0   \n",
       "\n",
       "  reviewCreatedVersion                   at replyContent repliedAt appVersion  \n",
       "0               2.73.0  2025-03-28 12:04:51          NaN       NaN     2.73.0  \n",
       "1               2.73.0  2025-03-28 01:34:11          NaN       NaN     2.73.0  \n",
       "2                  NaN  2025-03-27 22:11:08          NaN       NaN        NaN  \n",
       "3               2.73.0  2025-03-27 18:30:01          NaN       NaN     2.73.0  \n",
       "4               2.73.0  2025-03-27 17:12:54          NaN       NaN     2.73.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17958 entries, 0 to 17957\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   reviewId              17958 non-null  object\n",
      " 1   userName              17958 non-null  object\n",
      " 2   userImage             17958 non-null  object\n",
      " 3   content               17958 non-null  object\n",
      " 4   score                 17958 non-null  int64 \n",
      " 5   thumbsUpCount         17958 non-null  int64 \n",
      " 6   reviewCreatedVersion  13806 non-null  object\n",
      " 7   at                    17958 non-null  object\n",
      " 8   replyContent          408 non-null    object\n",
      " 9   repliedAt             408 non-null    object\n",
      " 10  appVersion            13806 non-null  object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewId                    0\n",
       "userName                    0\n",
       "userImage                   0\n",
       "content                     0\n",
       "score                       0\n",
       "thumbsUpCount               0\n",
       "reviewCreatedVersion     4152\n",
       "at                          0\n",
       "replyContent            17550\n",
       "repliedAt               17550\n",
       "appVersion               4152\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['replyContent', 'repliedAt','reviewCreatedVersion','appVersion'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17958 entries, 0 to 17957\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   reviewId       17958 non-null  object\n",
      " 1   userName       17958 non-null  object\n",
      " 2   userImage      17958 non-null  object\n",
      " 3   content        17958 non-null  object\n",
      " 4   score          17958 non-null  int64 \n",
      " 5   thumbsUpCount  17958 non-null  int64 \n",
      " 6   at             17958 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 982.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # menghapus mention\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # menghapus hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # menghapus RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # menghapus link\n",
    "    text = re.sub(r'[0-9]+', '', text) # menghapus angka\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # menghapus karakter selain huruf dan angka\n",
    " \n",
    "    text = text.replace('\\n', ' ') # mengganti baris baru dengan spasi\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # menghapus semua tanda baca\n",
    "    text = text.strip(' ') # menghapus karakter spasi dari kiri dan kanan teks\n",
    "    return text\n",
    "\n",
    "def casefoldingText(text): # Mengubah semua karakter dalam teks menjadi huruf kecil\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Terapkan cleaning pada kolom 'content'\n",
    "df['cleaned_content'] = df['content'].apply(cleaningText)\n",
    "df['cleaned_casefolding_content'] = df['cleaned_content'].apply(casefoldingText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_dict = {\"gk\": \"tidak\",\"ga\": \"tidak\",\"nggak\": \"tidak\",\"ngga\": \"tidak\",\"bgt\": \"banget\",\"bener\": \"benar\",\"tp\": \"tapi\",\"dgn\": \"dengan\",\n",
    "    \"udh\": \"sudah\", \"aja\": \"saja\", \"blm\": \"belum\", \"sy\": \"saya\", \"dg\": \"dengan\", \"krn\": \"karena\", \"dr\": \"dari\", \"sm\": \"sama\", \"trs\": \"terus\", \n",
    "    \"jg\": \"juga\", \"ny\": \"nya\", \n",
    "}\n",
    "\n",
    "def fixing_slangwords(text):\n",
    "    words = text.split()\n",
    "    fixed_words = []\n",
    " \n",
    "    for word in words:\n",
    "        if word.lower() in slang_dict:\n",
    "            fixed_words.append(slang_dict[word.lower()])\n",
    "        else:\n",
    "            fixed_words.append(word)\n",
    " \n",
    "    fixed_text = ' '.join(fixed_words)\n",
    "    return fixed_text\n",
    "\n",
    "df['cleaned_slang_content'] = df['cleaned_casefolding_content'].apply(fixing_slangwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizingText(text): # Memecah atau membagi string, teks menjadi daftar token\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "df['tokenized_content'] = df['cleaned_slang_content'].apply(tokenizingText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filteringText(text): # Menghapus stopwords dalam teks\n",
    "    listStopwords = set(stopwords.words('indonesian'))\n",
    "    listStopwords1 = set(stopwords.words('english'))\n",
    "    listStopwords.update(listStopwords1)\n",
    "    listStopwords.update(['iya','yaa','gak','nya','na','sih','ku',\"di\",\"ga\",\"ya\",\"gaa\",\"loh\",\"kah\",\"woi\",\"woii\",\"woy\"])\n",
    "    filtered = []\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered\n",
    "    return text\n",
    "\n",
    "df['stopword_tokenized_content'] = df['tokenized_content'].apply(filteringText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m     stemmed_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(stemmed_words)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stemmed_text\n\u001b[1;32m---> 17\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_content\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstopword_tokenized_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(stemmingText)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4759\u001b[0m         func,\n\u001b[0;32m   4760\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4761\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4762\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4763\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4764\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1290\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1291\u001b[0m )\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m, in \u001b[0;36mstemmingText\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      7\u001b[0m words \u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Menerapkan stemming pada setiap kata dalam daftar\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m stemmed_words \u001b[38;5;241m=\u001b[39m [stemmer\u001b[38;5;241m.\u001b[39mstem(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Menggabungkan kata-kata yang telah distem\u001b[39;00m\n\u001b[0;32m     13\u001b[0m stemmed_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(stemmed_words)\n",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m words \u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Menerapkan stemming pada setiap kata dalam daftar\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m stemmed_words \u001b[38;5;241m=\u001b[39m [stemmer\u001b[38;5;241m.\u001b[39mstem(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Menggabungkan kata-kata yang telah distem\u001b[39;00m\n\u001b[0;32m     13\u001b[0m stemmed_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(stemmed_words)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\Sastrawi\\Stemmer\\CachedStemmer.py:20\u001b[0m, in \u001b[0;36mCachedStemmer.stem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     18\u001b[0m     stems\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mget(word))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m     stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelegatedStemmer\u001b[38;5;241m.\u001b[39mstem(word)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mset(word, stem)\n\u001b[0;32m     22\u001b[0m     stems\u001b[38;5;241m.\u001b[39mappend(stem)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py:27\u001b[0m, in \u001b[0;36mStemmer.stem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     24\u001b[0m stems \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[1;32m---> 27\u001b[0m     stems\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstem_word(word))\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(stems)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py:36\u001b[0m, in \u001b[0;36mStemmer.stem_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstem_plural_word(word)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstem_singular_word(word)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py:84\u001b[0m, in \u001b[0;36mStemmer.stem_singular_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Stem a singular word to its common stem form.\"\"\"\u001b[39;00m\n\u001b[0;32m     83\u001b[0m context \u001b[38;5;241m=\u001b[39m Context(word, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisitor_provider)\n\u001b[1;32m---> 84\u001b[0m context\u001b[38;5;241m.\u001b[39mexecute()\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:37\u001b[0m, in \u001b[0;36mContext.execute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute stemming process; the result can be retrieved with result\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#step 1 - 5\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_stemming_process()\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#step 6\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_word):\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:80\u001b[0m, in \u001b[0;36mContext.start_stemming_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m#step 4, 5\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_prefixes()\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_word):\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:89\u001b[0m, in \u001b[0;36mContext.remove_prefixes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_prefixes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m---> 89\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccept_prefix_visitors(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix_pisitors)\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_word):\n\u001b[0;32m     91\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:110\u001b[0m, in \u001b[0;36mContext.accept_prefix_visitors\u001b[1;34m(self, visitors)\u001b[0m\n\u001b[0;32m    108\u001b[0m removalCount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremovals)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m visitor \u001b[38;5;129;01min\u001b[39;00m visitors:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccept(visitor)\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_word):\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_word\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:97\u001b[0m, in \u001b[0;36mContext.accept\u001b[1;34m(self, visitor)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccept\u001b[39m(\u001b[38;5;28mself\u001b[39m, visitor):\n\u001b[1;32m---> 97\u001b[0m     visitor\u001b[38;5;241m.\u001b[39mvisit(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Visitor\\AbstractDisambiguatePrefixRule.py:14\u001b[0m, in \u001b[0;36mAbstractDisambiguatePrefixRule.visit\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m     11\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m disambiguator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisambiguators:\n\u001b[1;32m---> 14\u001b[0m     result \u001b[38;5;241m=\u001b[39m disambiguator\u001b[38;5;241m.\u001b[39mdisambiguate(context\u001b[38;5;241m.\u001b[39mcurrent_word)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mdictionary\u001b[38;5;241m.\u001b[39mcontains(result):\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\Sastrawi\\Morphology\\Disambiguator\\DisambiguatorPrefixRule40.py:21\u001b[0m, in \u001b[0;36mDisambiguatorPrefixRule40b.disambiguate\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDisambiguatorPrefixRule40b\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Disambiguate Prefix Rule 40b (CC infix rules)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    Rule 40b : CinV -> CV\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdisambiguate\u001b[39m(\u001b[38;5;28mself\u001b[39m, word):\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"Disambiguate Prefix Rule 40b (CC infix rules)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m        Rule 40b : CinV -> CV\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m         matches \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^([bcdfghjklmnpqrstvwxyz])in([aiueo])(.*)$\u001b[39m\u001b[38;5;124m'\u001b[39m, word)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def stemmingText(text): # Mengurangi kata ke bentuk dasarnya yang menghilangkan imbuhan awalan dan akhiran atau ke akar kata\n",
    "    # Membuat objek stemmer\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "\n",
    "    # Memecah teks menjadi daftar kata\n",
    "    words = text\n",
    "\n",
    "    # Menerapkan stemming pada setiap kata dalam daftar\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Menggabungkan kata-kata yang telah distem\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "\n",
    "    return stemmed_text\n",
    "\n",
    "df['final_content'] = df['stopword_tokenized_content'].apply(stemmingText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>at</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>cleaned_casefolding_content</th>\n",
       "      <th>cleaned_slang_content</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>stopword_tokenized_content</th>\n",
       "      <th>stemmed_tokenized_content</th>\n",
       "      <th>final_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>061a9c37-9da0-4afb-923d-b9b4f120a1e7</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>event nya banyak tambah lagi event nya terus</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-28 12:04:51</td>\n",
       "      <td>event nya banyak tambah lagi event nya terus</td>\n",
       "      <td>event nya banyak tambah lagi event nya terus</td>\n",
       "      <td>event nya banyak tambah lagi event nya terus</td>\n",
       "      <td>[event, nya, banyak, tambah, lagi, event, nya,...</td>\n",
       "      <td>[event, event]</td>\n",
       "      <td>event event</td>\n",
       "      <td>e v e n t   e v e n t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b17544bc-2268-49a5-afa7-747f4484fd59</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>lebih bagus lagi ini game mod miring deh</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-28 01:34:11</td>\n",
       "      <td>lebih bagus lagi ini game mod miring deh</td>\n",
       "      <td>lebih bagus lagi ini game mod miring deh</td>\n",
       "      <td>lebih bagus lagi ini game mod miring deh</td>\n",
       "      <td>[lebih, bagus, lagi, ini, game, mod, miring, deh]</td>\n",
       "      <td>[bagus, game, mod, miring, deh]</td>\n",
       "      <td>bagus game mod miring deh</td>\n",
       "      <td>b a g u s   g a m e   m o d   m i r i n g   d e h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a6dcf278-4c53-4afd-ba34-ddbf9031d62e</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>bagus banget gamenya</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-27 22:11:08</td>\n",
       "      <td>bagus banget gamenya</td>\n",
       "      <td>bagus banget gamenya</td>\n",
       "      <td>bagus banget gamenya</td>\n",
       "      <td>[bagus, banget, gamenya]</td>\n",
       "      <td>[bagus, banget, gamenya]</td>\n",
       "      <td>bagus banget gamenya</td>\n",
       "      <td>b a g u s   b a n g e t   g a m e n y a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6517e761-e80e-4c8f-9e7d-40bf5092d455</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>bagus dan menghibur 3d sangat enak di lihat mata</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-27 18:30:01</td>\n",
       "      <td>bagus dan menghibur d sangat enak di lihat mata</td>\n",
       "      <td>bagus dan menghibur d sangat enak di lihat mata</td>\n",
       "      <td>bagus dan menghibur d sangat enak di lihat mata</td>\n",
       "      <td>[bagus, dan, menghibur, d, sangat, enak, di, l...</td>\n",
       "      <td>[bagus, menghibur, enak, lihat, mata]</td>\n",
       "      <td>bagus hibur enak lihat mata</td>\n",
       "      <td>b a g u s   h i b u r   e n a k   l i h a t   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0943c392-06e9-49f1-a361-aacf643c8880</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Tolong di jelaskan kenapa akun saya di ban den...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-27 17:12:54</td>\n",
       "      <td>Tolong di jelaskan kenapa akun saya di ban den...</td>\n",
       "      <td>tolong di jelaskan kenapa akun saya di ban den...</td>\n",
       "      <td>tolong di jelaskan kenapa akun saya di ban den...</td>\n",
       "      <td>[tolong, di, jelaskan, kenapa, akun, saya, di,...</td>\n",
       "      <td>[tolong, akun, ban, alasan, penyalahgunaan, ke...</td>\n",
       "      <td>tolong akun ban alas penyalahgunaan mana banding</td>\n",
       "      <td>t o l o n g   a k u n   b a n   a l a s   p e ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId         userName  \\\n",
       "0  061a9c37-9da0-4afb-923d-b9b4f120a1e7  Pengguna Google   \n",
       "1  b17544bc-2268-49a5-afa7-747f4484fd59  Pengguna Google   \n",
       "2  a6dcf278-4c53-4afd-ba34-ddbf9031d62e  Pengguna Google   \n",
       "3  6517e761-e80e-4c8f-9e7d-40bf5092d455  Pengguna Google   \n",
       "4  0943c392-06e9-49f1-a361-aacf643c8880  Pengguna Google   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "3  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0       event nya banyak tambah lagi event nya terus      5              0   \n",
       "1           lebih bagus lagi ini game mod miring deh      2              0   \n",
       "2                               bagus banget gamenya      5              0   \n",
       "3   bagus dan menghibur 3d sangat enak di lihat mata      5              0   \n",
       "4  Tolong di jelaskan kenapa akun saya di ban den...      1              0   \n",
       "\n",
       "                    at                                    cleaned_content  \\\n",
       "0  2025-03-28 12:04:51       event nya banyak tambah lagi event nya terus   \n",
       "1  2025-03-28 01:34:11           lebih bagus lagi ini game mod miring deh   \n",
       "2  2025-03-27 22:11:08                               bagus banget gamenya   \n",
       "3  2025-03-27 18:30:01    bagus dan menghibur d sangat enak di lihat mata   \n",
       "4  2025-03-27 17:12:54  Tolong di jelaskan kenapa akun saya di ban den...   \n",
       "\n",
       "                         cleaned_casefolding_content  \\\n",
       "0       event nya banyak tambah lagi event nya terus   \n",
       "1           lebih bagus lagi ini game mod miring deh   \n",
       "2                               bagus banget gamenya   \n",
       "3    bagus dan menghibur d sangat enak di lihat mata   \n",
       "4  tolong di jelaskan kenapa akun saya di ban den...   \n",
       "\n",
       "                               cleaned_slang_content  \\\n",
       "0       event nya banyak tambah lagi event nya terus   \n",
       "1           lebih bagus lagi ini game mod miring deh   \n",
       "2                               bagus banget gamenya   \n",
       "3    bagus dan menghibur d sangat enak di lihat mata   \n",
       "4  tolong di jelaskan kenapa akun saya di ban den...   \n",
       "\n",
       "                                   tokenized_content  \\\n",
       "0  [event, nya, banyak, tambah, lagi, event, nya,...   \n",
       "1  [lebih, bagus, lagi, ini, game, mod, miring, deh]   \n",
       "2                           [bagus, banget, gamenya]   \n",
       "3  [bagus, dan, menghibur, d, sangat, enak, di, l...   \n",
       "4  [tolong, di, jelaskan, kenapa, akun, saya, di,...   \n",
       "\n",
       "                          stopword_tokenized_content  \\\n",
       "0                                     [event, event]   \n",
       "1                    [bagus, game, mod, miring, deh]   \n",
       "2                           [bagus, banget, gamenya]   \n",
       "3              [bagus, menghibur, enak, lihat, mata]   \n",
       "4  [tolong, akun, ban, alasan, penyalahgunaan, ke...   \n",
       "\n",
       "                          stemmed_tokenized_content  \\\n",
       "0                                       event event   \n",
       "1                         bagus game mod miring deh   \n",
       "2                              bagus banget gamenya   \n",
       "3                       bagus hibur enak lihat mata   \n",
       "4  tolong akun ban alas penyalahgunaan mana banding   \n",
       "\n",
       "                                       final_content  \n",
       "0                              e v e n t   e v e n t  \n",
       "1  b a g u s   g a m e   m o d   m i r i n g   d e h  \n",
       "2            b a g u s   b a n g e t   g a m e n y a  \n",
       "3  b a g u s   h i b u r   e n a k   l i h a t   ...  \n",
       "4  t o l o n g   a k u n   b a n   a l a s   p e ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca data kamus kata-kata positif dari GitHub\n",
    "lexicon_positive = dict()\n",
    " \n",
    "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_positive.csv')\n",
    "# Mengirim permintaan HTTP untuk mendapatkan file CSV dari GitHub\n",
    " \n",
    "if response.status_code == 200:\n",
    "    # Jika permintaan berhasil\n",
    "    reader = csv.reader(StringIO(response.text), delimiter=',')\n",
    "    # Membaca teks respons sebagai file CSV menggunakan pembaca CSV dengan pemisah koma\n",
    " \n",
    "    for row in reader:\n",
    "        # Mengulangi setiap baris dalam file CSV\n",
    "        lexicon_positive[row[0]] = int(row[1])\n",
    "        # Menambahkan kata-kata positif dan skornya ke dalam kamus lexicon_positive\n",
    "else:\n",
    "    print(\"Failed to fetch positive lexicon data\")\n",
    " \n",
    "# Membaca data kamus kata-kata negatif dari GitHub\n",
    "lexicon_negative = dict()\n",
    " \n",
    "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_negative.csv')\n",
    "# Mengirim permintaan HTTP untuk mendapatkan file CSV dari GitHub\n",
    " \n",
    "if response.status_code == 200:\n",
    "    # Jika permintaan berhasil\n",
    "    reader = csv.reader(StringIO(response.text), delimiter=',')\n",
    "    # Membaca teks respons sebagai file CSV menggunakan pembaca CSV dengan pemisah koma\n",
    " \n",
    "    for row in reader:\n",
    "        # Mengulangi setiap baris dalam file CSV\n",
    "        lexicon_negative[row[0]] = int(row[1])\n",
    "        # Menambahkan kata-kata negatif dan skornya dalam kamus lexicon_negative\n",
    "else:\n",
    "    print(\"Failed to fetch negative lexicon data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_lexicon_indonesia(text):\n",
    "    score = 0\n",
    "    # Inisialisasi skor sentimen ke 0\n",
    "\n",
    "    for word in text:\n",
    "        # Mengulangi setiap kata dalam teks\n",
    "\n",
    "        if word in lexicon_positive:\n",
    "            score += lexicon_positive[word]\n",
    "            # Jika kata ada dalam kamus positif, tambahkan skornya ke skor sentimen\n",
    "\n",
    "    for word in text:\n",
    "        # Mengulangi setiap kata dalam teks (sekali lagi)\n",
    "\n",
    "        if word in lexicon_negative:\n",
    "            score += lexicon_negative[word]\n",
    "            # Jika kata ada dalam kamus negatif, kurangkan skornya dari skor sentimen\n",
    "\n",
    "    polarity = ''\n",
    "    # Inisialisasi variabel polaritas\n",
    "\n",
    "    # Menambahkan kategori netral\n",
    "    if score > 0:\n",
    "        polarity = 'positive'\n",
    "        # Jika skor sentimen lebih besar dari 0, maka polaritas adalah positif\n",
    "    elif score < 0:\n",
    "        polarity = 'negative'\n",
    "        # Jika skor sentimen kurang dari 0, maka polaritas adalah negatif\n",
    "    else:\n",
    "        polarity = 'neutral'\n",
    "        # Jika skor sentimen sama dengan 0, maka polaritas adalah netral\n",
    "\n",
    "    return score, polarity\n",
    "    # Mengembalikan skor sentimen dan polaritas teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity\n",
      "neutral    17958\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "results = df['stemmed_tokenized_content'].apply(sentiment_analysis_lexicon_indonesia)\n",
    "results = list(zip(*results))\n",
    "df['polarity_score'] = results[0]\n",
    "df['polarity'] = results[1]\n",
    "print(df['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential()\n",
    "model_cnn.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model_cnn.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2))\n",
    "model_cnn.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(64, activation='relu'))\n",
    "model_cnn.add(Dropout(0.2))\n",
    "model_cnn.add(Dense(3, activation='softmax'))\n",
    "model_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_cnn.build(input_shape=(None, max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model_lstm.add(LSTM(128, return_sequences=True))\n",
    "model_lstm.add(LSTM(64))\n",
    "model_lstm.add(Dense(64, activation='relu'))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(3, activation='softmax'))\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_lstm.build(input_shape=(None, max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model_rnn.add(SimpleRNN(128, return_sequences=True))\n",
    "model_rnn.add(SimpleRNN(64))\n",
    "model_rnn.add(Dense(64, activation='relu'))\n",
    "model_rnn.add(Dropout(0.2))\n",
    "model_rnn.add(Dense(3, activation='softmax'))\n",
    "model_rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_rnn.build(input_shape=(None, max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
